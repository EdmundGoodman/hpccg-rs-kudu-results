run_configurations:
  "cpp-reference":
    sbatch_config:
      "nodes": 1
      "ntasks-per-node": 1
      "cpus-per-task": 1
      "exclusive": "mcs"
      "mem": 60000
    module_loads: []
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/0_cpp_versions/0_ref"
    build_commands:
      - "make no_yaml"
      - "make -j 8"
    run_command: "./test_HPCCG"

  "rust-reference":
    sbatch_config:
      "nodes": 1
      "ntasks-per-node": 1
      "cpus-per-task": 1
      "exclusive": "mcs"
      "mem": 60000
    module_loads: []
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/5_iterators"
    build_commands:
      - "cargo build --release"
    run_command: "./target/release/hpccg-rs"

  "cpp-openmp":
    sbatch_config:
      "nodes": 1
      "ntasks-per-node": 1
      "cpus-per-task": 32
      "exclusive": "mcs"
      "mem": 60000
    module_loads: []
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/0_cpp_versions/1_openmp"
    build_commands:
      - "make no_yaml"
      - "make -j 8"
    run_command: "./test_HPCCG"

  "rust-rayon":
    sbatch_config:
      "nodes": 1
      "ntasks-per-node": 1
      "cpus-per-task": 32
      "exclusive": "mcs"
      "mem": 60000
    module_loads: []
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/6_parallel"
    build_commands:
      - "cargo build --release"
    run_command: "./target/release/hpccg-rs"

  "cpp-mpi":
    sbatch_config:
      "cpus-per-task": 2
      "exclusive": "mcs"
      "mem": 60000
    module_loads:
      - "cs402-mpi"
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/0_cpp_versions/2_mpi"
    build_commands:
      - "make no_yaml"
      - "make -j 8"
    run_command: "mpirun ./test_HPCCG"

  "rust-mpi":
    sbatch_config:
      "cpus-per-task": 2
      "exclusive": "mcs"
      "mem": 60000
    module_loads:
      - "cs402-mpi"
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/7_mpi"
    build_commands:
      - "cargo build --release"
    run_command: "mpirun ./target/release/hpccg-rs"

  "cpp-hybrid":
    sbatch_config:
      "exclusive": "mcs"
      "mem": 60000
    module_loads:
      - "cs402-mpi"
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/0_cpp_versions/3_hybrid"
    build_commands:
      - "make no_yaml"
      - "make -j 8"
    run_command: "mpirun ./test_HPCCG"

  "rust-hybrid":
    sbatch_config:
      "exclusive": "mcs"
      "mem": 60000
    module_loads:
      - "cs402-mpi"
    environment_variables: {}
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/8_hybrid"
    build_commands:
      - "cargo build --release"
    run_command: "mpirun ./target/release/hpccg-rs"

  "cpp-kokkos":
    sbatch_config:
      "nodes": 1
      "ntasks-per-node": 1
      "cpus-per-task": 32
      "exclusive": "mcs"
      "mem": 60000
    module_loads: []
    environment_variables:
      "OMP_NUM_THREADS": 32
      "OMP_PROC_BIND": "spread"
      "OMP_PLACES": "threads"
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/0_cpp_versions/5_kokkos"
    build_commands:
      - "make no_yaml"
      - "make -j 8"
    run_command: "./test_HPCCG"

  "cpp-kokkos-mpi":
    sbatch_config:
      "exclusive": "mcs"
      "mem": 60000
    module_loads:
      - "cs402-mpi"
    environment_variables:
      "OMP_NUM_THREADS": 8
      "OMP_PROC_BIND": "spread"
      "OMP_PLACES": "threads"
    directory: "./generated_results/hpccg-rs-kudu-results/hpccg-rs/0_cpp_versions/6_kokkos_mpi"
    build_commands:
      - "make no_yaml"
      - "make -j 8"
    run_command: "mpirun ./test_HPCCG"

benches:
  "serial":
    run_configurations:
      - "cpp-reference"
      - "rust-reference"
    reruns:
      number: 5
      highest_discard: 1
      unaggregatable_metrics:
        - "Mesh x size"
        - "Mesh y size"
        - "Mesh z size"
        - "Mesh size"
    matrix:
      args:
        - "100 100 100"
        - "150 150 150"
        - "200 200 200"
        - "250 250 250"
        - "300 300 300"
    analysis:
      metrics:
        "Mesh x size": "nx: (\\d+)"
        "Mesh y size": "ny: (\\d+)"
        "Mesh z size": "nz: (\\d+)"
        "Total time (s)": "Time Summary:[\\s\\S]*Total\\s*: ([\\d\\.]+)[\\s\\S]*\nFLOPS Summary"
        "Wall time (s)": "real\\s([\\d\\.]+)\nuser"
      derived_metrics:
        "Execution time relative to C++": "metrics['Total time (s)'] / _corresponding_metrics['cpp-reference']['Total time (s)']"
        "Total speedup": "_sequential_metrics[0]['Total time (s)'] / metrics['Total time (s)']"
        "Mesh size": "int(metrics['Mesh x size']) * int(metrics['Mesh y size']) * int(metrics['Mesh z size'])"
      line_plots:
        - title: "Serial Implementation Comparison"
          x: "Mesh size"
          y: "Total time (s)"
        - title: "Serial Implementation Relative Execution Times"
          x: "Mesh size"
          y: "Execution time relative to C++"
        - title: "Serial Implementation Speedup"
          x: "Mesh size"
          y: "Total speedup"
      bar_charts:
        - title: "Serial Implementation Comparison"
          y: "Total time (s)"
          fix_metrics:
            "Mesh x size": "300"

  "multi-threaded":
    run_configurations:
      - "cpp-openmp"
      - "rust-rayon"
    reruns:
      number: 5
      highest_discard: 1
      unaggregatable_metrics:
        - "Mesh x size"
        - "Mesh y size"
        - "Mesh z size"
        - "Mesh size"
        - "Num threads"
    matrix:
      args:
        - "100 100 100"
        - "200 200 200"
        - "300 300 300"
        - "400 400 400"
      environment_variables:
        - { "OMP_NUM_THREADS": 1, "RAYON_NUM_THREADS": 1 }
        - { "OMP_NUM_THREADS": 8, "RAYON_NUM_THREADS": 8 }
        - { "OMP_NUM_THREADS": 32, "RAYON_NUM_THREADS": 32 }
    analysis:
      metrics:
        "Mesh x size": "nx: (\\d+)"
        "Mesh y size": "ny: (\\d+)"
        "Mesh z size": "nz: (\\d+)"
        "Num threads": "=== RUN INSTANTIATION ===\n\\{.*environment_variables: \\{.*OMP_NUM_THREADS: (\\d+),.*\\}"
        "Total time (s)": "Time Summary:[\\s\\S]*Total\\s*: ([\\d\\.]+)[\\s\\S]*\nFLOPS Summary"
        "Wall time (s)": "real\\s([\\d\\.]+)\nuser"
      derived_metrics:
        "Execution time relative to C++": "metrics['Total time (s)'] / _corresponding_metrics['cpp-openmp']['Total time (s)']"
        "Mesh size": "int(metrics['Mesh x size']) * int(metrics['Mesh y size']) * int(metrics['Mesh z size'])"
      line_plots:
        - title: "Multi-Threaded Implementation Comparison"
          x: "Mesh size"
          y: "Total time (s)"
          split_metrics:
            - "Num threads"
        - title: "Multi-Threaded Implementation Comparison"
          x: "Mesh size"
          y: "Total time (s)"
          fix_metrics:
            "Num threads": 32
        - title: "Multi-Threaded Implementation Relative Execution Times"
          x: "Mesh size"
          y: "Execution time relative to C++"
          split_metrics:
            - "Num threads"
      bar_charts:
        - title: "Multi-Threaded Implementation Comparison"
          y: "Total time (s)"
          split_metrics:
            - "Num threads"
          fix_metrics:
            "Mesh x size": "400"

  "mpi":
    run_configurations:
      - "cpp-mpi"
      - "rust-mpi"
    reruns:
      number: 5
      highest_discard: 1
      unaggregatable_metrics:
        - "Mesh x size"
        - "Mesh y size"
        - "Mesh z size"
        - "Mesh size"
        - "Nodes"
        - "Tasks"
    matrix:
      args:
        - "25 25 25"
        - "50 50 50"
        - "100 100 100"
        - "200 200 200"
        - "300 300 300"
        - "400 400 400"
      sbatch_config:
        - { "nodes": 2, "ntasks-per-node": 2 }
    analysis:
      metrics:
        "Mesh x size": "nx: (\\d+)"
        "Mesh y size": "ny: (\\d+)"
        "Mesh z size": "nz: (\\d+)"
        "Nodes": "=== SLURM CONFIG ===[\\s\\S]*NumNodes=(\\d+)"
        "Tasks": "=== SLURM CONFIG ===[\\s\\S]*NumTasks=(\\d+)"
        "Total time (s)": "Time Summary:[\\s\\S]*Total\\s*: ([\\d\\.]+)[\\s\\S]*\nFLOPS Summary"
        "Wall time (s)": "real\\s([\\d\\.]+)\nuser"
      derived_metrics:
        "Execution time relative to C++": "metrics['Total time (s)'] / _corresponding_metrics['cpp-mpi']['Total time (s)']"
        "Mesh size": "int(metrics['Mesh x size']) * int(metrics['Mesh y size']) * int(metrics['Mesh z size'])"
      line_plots:
        - title: "MPI Implementation Comparison"
          x: "Mesh size"
          y: "Total time (s)"
          split_metrics:
            - "Nodes"
            - "Tasks"
        - title: "MPI Implementation Relative Execution Times"
          x: "Mesh size"
          y: "Execution time relative to C++"
          split_metrics:
            - "Nodes"
            - "Tasks"
      bar_charts:
        - title: "MPI Implementation Comparison"
          y: "Total time (s)"
          split_metrics:
            - "Nodes"
            - "Tasks"
          fix_metrics:
            "Mesh x size": "300"

  "hybrid":
    run_configurations:
      - "cpp-hybrid"
      - "rust-hybrid"
    reruns:
      number: 5
      highest_discard: 1
      unaggregatable_metrics:
        - "Mesh x size"
        - "Mesh y size"
        - "Mesh z size"
        - "Mesh size"
        - "Nodes"
        - "Tasks per Node"
        - "Threads"
    matrix:
      args:
        - "25 25 25"
        - "50 50 50"
        - "100 100 100"
        - "200 200 200"
        - "300 300 300"
        - "400 400 400"
      [sbatch_config, environment_variables]:
        - [
            { "nodes": 2, "ntasks-per-node": 2, "cpus-per-task": 20 },
            { "OMP_NUM_THREADS": 20, "RAYON_NUM_THREADS": 20 },
          ]
    analysis:
      metrics:
        "Mesh x size": "nx: (\\d+)"
        "Mesh y size": "ny: (\\d+)"
        "Mesh z size": "nz: (\\d+)"
        "Nodes": "=== SLURM CONFIG ===[\\s\\S]*NumNodes=(\\d+)"
        "Tasks": "=== SLURM CONFIG ===[\\s\\S]*NumTasks=(\\d+)"
        "Threads": "=== RUN INSTANTIATION ===\n\\{.*sbatch_config: \\{.*cpus-per-task: (\\d+).*\\}"
        "Total time (s)": "Time Summary:[\\s\\S]*Total\\s*: ([\\d\\.]+)[\\s\\S]*\nFLOPS Summary"
        "Wall time (s)": "real\\s([\\d\\.]+)\nuser"
      derived_metrics:
        "Execution time relative to C++": "metrics['Total time (s)'] / _corresponding_metrics['cpp-hybrid']['Total time (s)']"
        "Total speedup": "_sequential_metrics[0]['Total time (s)'] / metrics['Total time (s)']"
        "Mesh size": "int(metrics['Mesh x size']) * int(metrics['Mesh y size']) * int(metrics['Mesh z size'])"
      line_plots:
        - title: "MPI & Multi-Threading Implementation Comparison"
          x: "Mesh size"
          y: "Total time (s)"
        - title: "MPI & Multi-Threading Implementation Relative Execution Times"
          x: "Mesh size"
          y: "Execution time relative to C++"
        - title: "MPI & Multi-Threading Implementation Speedup"
          x: "Mesh size"
          y: "Total speedup"
      bar_charts:
        - title: "MPI & Multi-Threading Implementation Comparison"
          y: "Total time (s)"
          fix_metrics:
            "Mesh x size": "300"

  "cpp-kokkos-rust-parallel":
    run_configurations:
      - "cpp-openmp"
      - "cpp-kokkos"
      - "rust-rayon"
    reruns:
      number: 5
      highest_discard: 1
      unaggregatable_metrics:
        - "Mesh x size"
        - "Mesh y size"
        - "Mesh z size"
        - "Mesh size"
    matrix:
      args:
        - "25 25 25"
        - "50 50 50"
        - "100 100 100"
        - "200 200 200"
        - "300 300 300"
        - "400 400 400"
      environment_variables:
        - { "OMP_NUM_THREADS": 32, "RAYON_NUM_THREADS": 32 }
    analysis:
      metrics:
        "Mesh x size": "nx: (\\d+)"
        "Mesh y size": "ny: (\\d+)"
        "Mesh z size": "nz: (\\d+)"
        "Total time (s)": "Time Summary:[\\s\\S]*Total\\s*: ([\\d\\.]+)[\\s\\S]*\nFLOPS Summary"
        "Wall time (s)": "real\\s([\\d\\.]+)\nuser"
      derived_metrics:
        "Execution time relative to C++": "metrics['Total time (s)'] / _corresponding_metrics['cpp-openmp']['Total time (s)']"
        "Total speedup": "_sequential_metrics[0]['Total time (s)'] / metrics['Total time (s)']"
        "Mesh size": "int(metrics['Mesh x size']) * int(metrics['Mesh y size']) * int(metrics['Mesh z size'])"
      line_plots:
        - title: "C++, Kokkos, and Rust with Multi-Threading Version Comparison"
          x: "Mesh size"
          y: "Total time (s)"
        - title: "C++, Kokkos, and Rust with Multi-Threading Relative Execution Times"
          x: "Mesh size"
          y: "Execution time relative to C++"
        - title: "C++, Kokkos, and Rust with Multi-Threading Implementation Speedup"
          x: "Mesh size"
          y: "Total speedup"
      bar_charts:
        - title: "C++, Kokkos, and Rust with Multi-Threading Version Comparison"
          y: "Total time (s)"
          fix_metrics:
            "Mesh x size": 400

  "cpp-kokkos-rust-hybrid":
    enabled: False
    run_configurations:
      - "cpp-hybrid"
      - "cpp-kokkos-mpi"
      - "rust-hybrid"
    reruns:
      number: 5
      highest_discard: 1
      unaggregatable_metrics:
        - "Mesh x size"
        - "Mesh y size"
        - "Mesh z size"
        - "Mesh size"
    matrix:
      args:
        - "25 25 25"
        - "50 50 50"
        - "100 100 100"
        - "150 150 150"
        - "200 200 200"
        - "250 250 250"
      [sbatch_config, environment_variables]:
        - [
            { "nodes": 2, "ntasks-per-node": 2, "cpus-per-task": 20 },
            { "OMP_NUM_THREADS": 20, "RAYON_NUM_THREADS": 20 },
          ]
    analysis:
      metrics:
        "Mesh x size": "nx: (\\d+)"
        "Mesh y size": "ny: (\\d+)"
        "Mesh z size": "nz: (\\d+)"
        "Total time (s)": "Time Summary:[\\s\\S]*Total\\s*: ([\\d\\.]+)[\\s\\S]*\nFLOPS Summary"
        "Wall time (s)": "real\\s([\\d\\.]+)\nuser"
      derived_metrics:
        "Execution time relative to C++": "metrics['Total time (s)'] / _corresponding_metrics['cpp-hybrid']['Total time (s)']"
        "Total speedup": "_sequential_metrics[0]['Total time (s)'] / metrics['Total time (s)']"
        "Mesh size": "int(metrics['Mesh x size']) * int(metrics['Mesh y size']) * int(metrics['Mesh z size'])"
      line_plots:
        - title: "C++, Kokkos, and Rust with MPI & Multi-Threading Version Comparison"
          x: "Mesh size"
          y: "Total time (s)"
        - title: "C++, Kokkos, and Rust with MPI & Multi-Threading Relative Execution Times"
          x: "Mesh size"
          y: "Execution time relative to C++"
        - title: "C++, Kokkos, and Rust with MPI & Multi-Threading Implementation Speedup"
          x: "Mesh size"
          y: "Total speedup"
      bar_charts:
        - title: "C++, Kokkos, and Rust with MPI & Multi-Threading Version Comparison"
          y: "Wall time (s)"
          fix_metrics:
            "Mesh x size": 200
